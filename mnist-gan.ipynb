{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-21 03:32:00.710000: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-21 03:32:06.656118: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2024-07-21 03:32:06.657173: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2024-07-21 03:32:06.657186: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_rows = 28\n",
    "img_cols = 28\n",
    "channels = 1\n",
    "img_shape = (img_rows, img_cols, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "\n",
    "    noise_shape = (100,)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(256, input_shape=noise_shape, activation=\"swish\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dense(512, activation=\"swish\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dense(1024, activation=\"swish\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    \n",
    "    model.add(Dense(np.prod(img_shape), activation='tanh'))\n",
    "    model.add(Reshape(img_shape))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    noise = Input(shape=noise_shape)\n",
    "    img = model(noise)\n",
    "\n",
    "    return Model(noise, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Flatten(input_shape=img_shape))\n",
    "    model.add(Dense(512, activation=\"swish\"))\n",
    "    model.add(Dense(256, activation=\"swish\"))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.summary()\n",
    "\n",
    "    img = Input(shape=img_shape)\n",
    "    validity = model(img)\n",
    "\n",
    "    return Model(img, validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(X_train, _), (_, _) = mnist.load_data()\n",
    "X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "X_train = np.expand_dims(X_train, axis=3) \n",
    "\n",
    "def train(epochs, batch_size=128, save_interval=50):\n",
    "    half_batch = int(batch_size / 2)\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "        imgs = X_train[idx]\n",
    " \n",
    "        noise = np.random.normal(0, 1, (half_batch, 100))\n",
    "\n",
    "        gen_imgs = generator.predict(noise, verbose=None)\n",
    "\n",
    "        d_loss_real = discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "        d_loss_fake = discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake) \n",
    "        \n",
    "        noise = np.random.normal(0, 1, (batch_size, 100)) \n",
    "        valid_y = np.array([1] * batch_size) \n",
    "        g_loss = combined.train_on_batch(noise, valid_y)\n",
    "        \n",
    "        if epoch % save_interval == 0:\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "        \n",
    "        if epoch % save_interval == 0:\n",
    "            save_imgs(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_imgs(epoch):\n",
    "    r, c = 5, 5\n",
    "    noise = np.random.normal(0, 1, (r * c, 100))\n",
    "    gen_imgs = generator.predict(noise, verbose=None)\n",
    "\n",
    "    # Rescale images 0 - 1\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "            axs[i,j].axis('off')\n",
    "            cnt += 1\n",
    "    fig.savefig(\"images/mnist_%d.png\" % epoch)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(0.0002, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 533,505\n",
      "Trainable params: 533,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-21 03:32:11.576050: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2024-07-21 03:32:11.576469: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-07-21 03:32:11.576498: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tensorflow-2-11-20240721-084422): /proc/driver/nvidia/version does not exist\n",
      "2024-07-21 03:32:11.577551: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 256)               25856     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256)              1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1024)              525312    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 1024)             4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 784)               803600    \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,493,520\n",
      "Trainable params: 1,489,936\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = build_generator()\n",
    "generator.compile(loss='binary_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "z = Input(shape=(100,))\n",
    "img = generator(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "discriminator.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid = discriminator(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined = Model(z, valid)\n",
    "combined.compile(loss='binary_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "795f2b237a254362807bd2f7e92ad01e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.495104, acc.: 68.75%] [G loss: 0.693618]\n",
      "500 [D loss: 0.654013, acc.: 71.88%] [G loss: 0.931246]\n",
      "1000 [D loss: 0.612889, acc.: 70.31%] [G loss: 1.287784]\n",
      "1500 [D loss: 0.568697, acc.: 67.19%] [G loss: 1.218674]\n",
      "2000 [D loss: 0.605150, acc.: 70.31%] [G loss: 1.028729]\n",
      "2500 [D loss: 0.647692, acc.: 53.91%] [G loss: 0.995970]\n",
      "3000 [D loss: 0.684186, acc.: 57.03%] [G loss: 0.947785]\n",
      "3500 [D loss: 0.635038, acc.: 65.62%] [G loss: 0.914529]\n",
      "4000 [D loss: 0.632911, acc.: 57.03%] [G loss: 0.877610]\n",
      "4500 [D loss: 0.700603, acc.: 53.12%] [G loss: 0.855702]\n",
      "5000 [D loss: 0.671966, acc.: 52.34%] [G loss: 0.803368]\n",
      "5500 [D loss: 0.667962, acc.: 55.47%] [G loss: 0.837979]\n",
      "6000 [D loss: 0.687010, acc.: 56.25%] [G loss: 0.803477]\n",
      "6500 [D loss: 0.689008, acc.: 48.44%] [G loss: 0.833392]\n",
      "7000 [D loss: 0.661363, acc.: 58.59%] [G loss: 0.834184]\n",
      "7500 [D loss: 0.654292, acc.: 55.47%] [G loss: 0.850133]\n",
      "8000 [D loss: 0.623146, acc.: 70.31%] [G loss: 0.853918]\n",
      "8500 [D loss: 0.674765, acc.: 53.12%] [G loss: 0.853622]\n",
      "9000 [D loss: 0.685771, acc.: 52.34%] [G loss: 0.846409]\n",
      "9500 [D loss: 0.655378, acc.: 64.06%] [G loss: 0.877993]\n",
      "10000 [D loss: 0.667802, acc.: 64.06%] [G loss: 0.876367]\n",
      "10500 [D loss: 0.646189, acc.: 60.94%] [G loss: 0.888527]\n",
      "11000 [D loss: 0.639814, acc.: 57.81%] [G loss: 0.907922]\n",
      "11500 [D loss: 0.621010, acc.: 66.41%] [G loss: 0.918494]\n",
      "12000 [D loss: 0.632733, acc.: 60.94%] [G loss: 0.901758]\n",
      "12500 [D loss: 0.618546, acc.: 64.06%] [G loss: 1.006296]\n",
      "13000 [D loss: 0.633307, acc.: 60.16%] [G loss: 0.998123]\n",
      "13500 [D loss: 0.605442, acc.: 64.06%] [G loss: 0.963241]\n",
      "14000 [D loss: 0.606768, acc.: 67.19%] [G loss: 0.962470]\n",
      "14500 [D loss: 0.636571, acc.: 64.06%] [G loss: 0.993972]\n",
      "15000 [D loss: 0.553949, acc.: 74.22%] [G loss: 0.978448]\n",
      "15500 [D loss: 0.549089, acc.: 72.66%] [G loss: 1.035883]\n",
      "16000 [D loss: 0.620285, acc.: 60.94%] [G loss: 0.986320]\n",
      "16500 [D loss: 0.642145, acc.: 65.62%] [G loss: 1.054764]\n",
      "17000 [D loss: 0.558579, acc.: 68.75%] [G loss: 1.019079]\n",
      "17500 [D loss: 0.615199, acc.: 65.62%] [G loss: 1.067288]\n",
      "18000 [D loss: 0.633331, acc.: 62.50%] [G loss: 1.098311]\n",
      "18500 [D loss: 0.632583, acc.: 60.16%] [G loss: 1.061602]\n",
      "19000 [D loss: 0.589727, acc.: 71.88%] [G loss: 1.112940]\n",
      "19500 [D loss: 0.514671, acc.: 72.66%] [G loss: 1.072894]\n",
      "20000 [D loss: 0.572867, acc.: 71.88%] [G loss: 1.102080]\n",
      "20500 [D loss: 0.545078, acc.: 71.88%] [G loss: 1.074484]\n",
      "21000 [D loss: 0.526626, acc.: 74.22%] [G loss: 1.184149]\n",
      "21500 [D loss: 0.540981, acc.: 73.44%] [G loss: 1.158552]\n",
      "22000 [D loss: 0.569414, acc.: 67.19%] [G loss: 1.210324]\n",
      "22500 [D loss: 0.520148, acc.: 78.12%] [G loss: 1.192881]\n",
      "23000 [D loss: 0.571374, acc.: 69.53%] [G loss: 1.206004]\n",
      "23500 [D loss: 0.532992, acc.: 74.22%] [G loss: 1.187697]\n",
      "24000 [D loss: 0.516784, acc.: 69.53%] [G loss: 1.112465]\n",
      "24500 [D loss: 0.549969, acc.: 71.09%] [G loss: 1.195304]\n"
     ]
    }
   ],
   "source": [
    "train(epochs=25000, batch_size=128, save_interval=500)\n",
    "generator.save('generator_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m123"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
